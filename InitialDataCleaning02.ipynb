{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa883f2",
   "metadata": {},
   "source": [
    "# Initial Data Cleaning\n",
    "This script is designed to fill in nulls in important missing fields and to format and select the data which will be required to create a model later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a24c1",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac80599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc31857",
   "metadata": {},
   "source": [
    "## Filling in Nulls\n",
    "To fill in nulls in this process we need some background on the data itself and how I intend to use it. First off, the dataset of interest contains over 2 million rows - each of which pertains to a specific wildfire. For each fire there is a Latitude and Longitude point for where the fire originated. Also, in most rows there are county and state code identifiers, however, in many rows (approx. 600K) there are no county identifiers. The lack of those county identifiers is an issue since we intend to analyze and predict wildfires on a county level. \n",
    "\n",
    "To address the issue of the missing county identifiers we take the following actions:\n",
    "\n",
    "1. From an online source, get a data set which has Geofences (Polygons) for all the counties in the U.S. \n",
    "2. From the U.S. Census Bureau get a correlation of all the counties and states with their correct code \n",
    "3. Merge the county polygons to the county/state codes based on the county name and state abbreviation\n",
    "4. In the wildfire data create spatial Points out of the longitude and latitude columns\n",
    "5. Execute a Spatial merge between the wildfire Points and the county Polygons based on whether the Point is in the Polygon\n",
    "6. Extract the county/state codes from the merged dataframe and then subset to the desired columns for further cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e406d29",
   "metadata": {},
   "source": [
    "Read in the .shp file which has all of the Polygons for the U.S. counties. Subset to just the three needed columns: county name, country/state/county abbreviation (which we extract state abbreviation from), and the Polygon for the county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7143142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_2</th>\n",
       "      <th>HASC_2</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>US.AL.AU</td>\n",
       "      <td>POLYGON ((-86.81896 32.34027, -86.81084 32.347...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NAME_2    HASC_2                                           geometry\n",
       "0  Autauga  US.AL.AU  POLYGON ((-86.81896 32.34027, -86.81084 32.347..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf = gpd.read_file(\"./Data/CountyGeoFences/gadm36_USA_2.shp\")[[\"NAME_2\", \"HASC_2\", 'geometry']]\n",
    "geodf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdbc606",
   "metadata": {},
   "source": [
    "Create a new GeoDataFrame which reformats the county and state into the correct format to join on later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f94fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>AL</td>\n",
       "      <td>POLYGON ((-86.81896 32.34027, -86.81084 32.347...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COUNTY STATE                                           geometry\n",
       "0  AUTAUGA    AL  POLYGON ((-86.81896 32.34027, -86.81084 32.347..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = gpd.GeoDataFrame()\n",
    "new_df['COUNTY'] = geodf['NAME_2'].str.upper().str.strip()\n",
    "new_df['STATE'] = geodf['HASC_2'].str.slice(3,5).str.strip()\n",
    "new_df['geometry'] = geodf['geometry']\n",
    "\n",
    "new_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511c6961",
   "metadata": {},
   "source": [
    "Read in the Census data which correlates the county to the county/state code. In this data the *whole* states and the whole *US* are included, but are formatted so that their names are in all uppercase - whereas individual counties are in title case. So we filter out those rows which are already in upper case - as they are the whole states and whole US - which we are not interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8509cce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Areaname</th>\n",
       "      <th>STCOU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autauga, AL</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Areaname  STCOU\n",
       "2  Autauga, AL   1001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnd_data = pd.read_csv(\"./Data/CountyLandArea.csv\")[['Areaname', 'STCOU']]\n",
    "lnd_data = lnd_data.loc[lnd_data['Areaname'] != lnd_data['Areaname'].str.upper()]\n",
    "lnd_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744718e",
   "metadata": {},
   "source": [
    "Now format the data by separating the county name and the state abbreviation and by turning the code into a zero-padded five digit long value. For reference the code is built in a way such that the first two number indicate the state and the last three numbers indicate the county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1aebef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>AL</td>\n",
       "      <td>01001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COUNTY STATE FIPS_CODE\n",
       "2  AUTAUGA    AL     01001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lnd_data = pd.DataFrame()\n",
    "new_lnd_data['COUNTY'] = lnd_data['Areaname'].str.split(',').apply(lambda x: x[0].upper()).str.strip()\n",
    "new_lnd_data['STATE'] = lnd_data['Areaname'].str.split(',').apply(lambda x: x[1].upper()).str.strip()\n",
    "new_lnd_data['FIPS_CODE'] = lnd_data['STCOU'].astype(str).str.zfill(5)\n",
    "\n",
    "new_lnd_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a7c96c",
   "metadata": {},
   "source": [
    "Merge the county Polygon data with the Census data to get the county/state code with the Polygons. Then ensure that the object is a Spatial DataFrame with the correct geospatial reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e9f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = gpd.GeoDataFrame(pd.merge(new_lnd_data, new_df, on=['COUNTY', \"STATE\"], how='inner'), crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd0b84",
   "metadata": {},
   "source": [
    "#### Set that dataset aside. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48048b3",
   "metadata": {},
   "source": [
    "Read in the wildfire data from the .sqlite table, selecting (in SQL) only the few columns which we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f29557c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2/2/2005 0:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40.036944</td>\n",
       "      <td>-121.005833</td>\n",
       "      <td>06063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FOD_ID DISCOVERY_DATE  FIRE_SIZE   LATITUDE   LONGITUDE FIPS_CODE\n",
       "0       1  2/2/2005 0:00        0.1  40.036944 -121.005833     06063"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = sqlite3.connect('./Data/Fire/FPA_FOD_20210617.sqlite')\n",
    "query = \"SELECT f.FOD_ID, f.DISCOVERY_DATE, f.FIRE_SIZE, f.LATITUDE, f.LONGITUDE, f.FIPS_CODE from Fires f\"\n",
    "all_data = pd.read_sql_query(query, cursor)\n",
    "all_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad974bbe",
   "metadata": {},
   "source": [
    "Take the wildfire data and turn it into a Spatial DataFrame and create the geometry columns to be the Lat/Long points and ensure that the Spatial DataFrame has the correct reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf8dcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2/2/2005 0:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40.036944</td>\n",
       "      <td>-121.005833</td>\n",
       "      <td>06063</td>\n",
       "      <td>POINT (-121.00583 40.03694)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FOD_ID DISCOVERY_DATE  FIRE_SIZE   LATITUDE   LONGITUDE FIPS_CODE  \\\n",
       "0       1  2/2/2005 0:00        0.1  40.036944 -121.005833     06063   \n",
       "\n",
       "                      geometry  \n",
       "0  POINT (-121.00583 40.03694)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_fire_df = gpd.GeoDataFrame(all_data, geometry=gpd.points_from_xy(all_data.LONGITUDE, all_data.LATITUDE), crs=\"EPSG:4326\")\n",
    "geo_fire_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e0538",
   "metadata": {},
   "source": [
    "Now take both DataFrames - with the points (wildfire data) and with the polygons (county/state data)\n",
    "\n",
    "We will execute a spatial join such that we are joining the rows from the county/state data to the wildfire data wherever the Point in the wildfire data is *within* the Polygon of county/state data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04e25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = geo_fire_df.sjoin(comb, how='inner', predicate='within')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aba82e",
   "metadata": {},
   "source": [
    "There may be some duplicates because of overlap in counties or some edge cases within the data. So we remove those duplicates and retain only the first instance of the row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f8ad3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgd = merged.drop_duplicates(subset=[\"DISCOVERY_DATE\", \"FIRE_SIZE\", \"FIPS_CODE_right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadec6dc",
   "metadata": {},
   "source": [
    "## Formatting \n",
    "\n",
    "Now that we have the county/state codes filled in for all of our wildfire instances we can get to formatting the data. To format the data we will select just the few columns which we want and set the names correctly. Then we'll turn the discovery date into an actual date column and then finally calculate the discovery month of the fire - as we will be focused on monthly predictions of wildfires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82cacec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-02-02</td>\n",
       "      <td>0.1</td>\n",
       "      <td>06063</td>\n",
       "      <td>2005-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DISCOVERY_DATE  FIRE_SIZE FIPS_CODE      MONTH\n",
       "0     2005-02-02        0.1     06063 2005-02-01"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mgd = mgd[[\"DISCOVERY_DATE\", \"FIRE_SIZE\", \"FIPS_CODE_right\"]].rename({'FIPS_CODE_right': \"FIPS_CODE\"}, axis=1)\n",
    "final_mgd.loc[:, 'DISCOVERY_DATE'] = pd.to_datetime(final_mgd.loc[:, 'DISCOVERY_DATE'])\n",
    "final_mgd['MONTH'] = final_mgd['DISCOVERY_DATE'].to_numpy().astype('datetime64[M]')\n",
    "\n",
    "final_mgd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "068d61f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1857951, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mgd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff047eee",
   "metadata": {},
   "source": [
    "From this data we sum up all of the fire sizes for each month and county/state code (FIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b22796",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = final_mgd.groupby(by=['MONTH', 'FIPS_CODE']).agg({'FIRE_SIZE': sum}).reset_index()\n",
    "agg_data.rename({'FIRE_SIZE': 'TOTAL_BURN_AREA'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7059953",
   "metadata": {},
   "source": [
    "Now - we want to standardize the area burned by the size of the county itself. This way we can better assess the actual impact of the fires on the county since some small fires may be very impactful in certain counties (i.e. small ones) but large fires may not matter at all since it's really only a small portion of the county (i.e. in Alaska where the counties are larger than most states)\n",
    "\n",
    "To do this standardization we turn back to the census bureau and we can find the land size (in Sq. Miles) for all of the counties and then merge it to our aggregated data and then divide the Fire Size by the county size. We will convert the Sq. Miles into Acres for a better apples-apples comparison of total area to area burned. \n",
    "\n",
    "Also note that some fires may extend beyond one county - or start in one county and then blow directly into the neighnoring county - and while this may lead some of our numbers to be decieving, as a whole the concept is still strong. However, from a data perspective this does mean that total area burned may be greater than county area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e22e25ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS_CODE</th>\n",
       "      <th>COUNTY_AREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000</td>\n",
       "      <td>2.423952e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FIPS_CODE   COUNTY_AREA\n",
       "0     00000  2.423952e+09"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "land_area_data = pd.read_csv(\"./Data/CountyLandArea.csv\")[[\"STCOU\", \"LND010190D\"]]\n",
    "land_area_data.rename({'STCOU': \"FIPS_CODE\", \"LND010190D\": \"COUNTY_AREA\"}, axis=1, inplace=True)\n",
    "land_area_data['FIPS_CODE'] = land_area_data[\"FIPS_CODE\"].astype(str).str.zfill(5)\n",
    "land_area_data['COUNTY_AREA'] = land_area_data['COUNTY_AREA'] * 640\n",
    "land_area_data = land_area_data.iloc[np.where(land_area_data['COUNTY_AREA'] != 0)]\n",
    "\n",
    "land_area_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53154ae8",
   "metadata": {},
   "source": [
    "Now merge the aggregated data with the land area data and divide to get the burned to toal area ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "731810c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "      <th>TOTAL_BURN_AREA</th>\n",
       "      <th>COUNTY_AREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>01015</td>\n",
       "      <td>8.0</td>\n",
       "      <td>391904.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MONTH FIPS_CODE  TOTAL_BURN_AREA  COUNTY_AREA\n",
       "0 1992-01-01     01015              8.0     391904.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_and_area = pd.merge(agg_data, land_area_data, how='inner', on=['FIPS_CODE'])\n",
    "agg_and_area.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593002f1",
   "metadata": {},
   "source": [
    "We will keep the burn area and county data so that we can aggregate separately for state and national geographic areas. So output the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b845b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_and_area.to_csv(\"./Data/clean_fire_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9da7d",
   "metadata": {},
   "source": [
    "Our last step is to pull in some weather data, clean it and then join in based on the state for which the weather data pertains to. This data is kept separate for now but will be converted into a format where it can be easily joined into a state level aggregation of the wildfire data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0860a",
   "metadata": {},
   "source": [
    "First read in the weather data csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e55aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"California\", \"Arizona\", \"Colorado\", \"Montana\", \"Nevada\", \"Oregon\", \"Washington\", \"Idaho\", \"Utah\", \"NewMexico\", \n",
    "         \"Wyoming\"]\n",
    "data = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f\"./Data/Weather/{f}.csv\", parse_dates=['DATE'])[[\"NAME\", \"DATE\", \"PRCP\", \"TMAX\", \"TMIN\"]]\n",
    "    df[\"STATE\"] = df['NAME'].str.split(',').apply(lambda x: x[1]).str.strip().str.split(' ').apply(lambda x: x[0]).str.strip()\n",
    "    df.drop('NAME', axis=1, inplace=True)\n",
    "    data.append(df)\n",
    "weather_data = pd.concat(data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd99783d",
   "metadata": {},
   "source": [
    "Now, we will average out the measurements which we have for multiple stats down into measurements on a state level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db73bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grped_weather = weather_data.groupby(by=[\"STATE\", \"DATE\"]).mean().reset_index()\n",
    "grped_weather.rename({'DATE': 'MONTH'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d22bf",
   "metadata": {},
   "source": [
    "Now, once again, read in the Census data to get state codes - there is a bit of logic to extract the state codes but not too bad since we can use work we have already done to format the file correctly. In the end we can see that we do indeed end up with codes for our 50 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47d3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.read_csv(\"./Data/CountyLandArea.csv\")[[\"Areaname\", \"STCOU\"]]\n",
    "census_data = census_data.loc[census_data['Areaname'] != census_data['Areaname'].str.upper()]\n",
    "census_data['STATE'] = census_data['Areaname'].str.split(',').apply(lambda x: x[1].upper()).str.strip()\n",
    "census_data['STATE_CODE'] = census_data['STCOU'].astype(str).str.zfill(5).str.slice(0,2)\n",
    "census_data = census_data.drop_duplicates(subset=['STATE_CODE', 'STATE'])[[\"STATE\", \"STATE_CODE\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a2211",
   "metadata": {},
   "source": [
    "Now we will join the weather and census data together to get the state codes for our states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea858662",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_w_codes = pd.merge(grped_weather, census_data, how='inner', on='STATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe879b37",
   "metadata": {},
   "source": [
    "Now export the data to a csv file where we can pull it into our modelling efforts later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5515195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_w_codes.to_csv(\"./Data/cleaned_weather_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e89942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
